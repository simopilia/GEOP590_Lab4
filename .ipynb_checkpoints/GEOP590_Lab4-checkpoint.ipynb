{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Ambient noise tomography of Lake Toba\n",
    "\n",
    "The goal of this Lab is to introduce you to the package SeisLib, a collection of Python libraries that will allow you to download and process ambient noise data from publicly available stations, compute cross-correlations, extract phase velocities and invert for velocity structures. Many other functionalities exist, please visit the following web-page for a comprehensive documentation and whenever you encounter an issue:\n",
    "https://seislib.readthedocs.io/en/latest/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As usual, we begin by importing the libraries we need \n",
    "import numpy as np\n",
    "from obspy import UTCDateTime as UTC\n",
    "from seislib.an import ANDownloader\n",
    "from seislib.an import AmbientNoiseVelocity\n",
    "import matplotlib.pyplot as plt\n",
    "from seislib.tomography import RegularGrid\n",
    "from seislib.tomography import SeismicTomography\n",
    "from obspy import read_inventory\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.crs as ccrs\n",
    "from seislib.plotting import make_colorbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Download seismic data\n",
    "\n",
    "To begin with, we have to download the continuous seismic records from one or more networks. This is done by first creating a dictionary that contains the information about our study area (i.e., where we want to search for data), and subsequently invoking the function ANDownloader to download the data in our local machine. Note that downloading the data typically takes several days.\n",
    "\n",
    "Check out more info about the seismic data (and the region where the stations were deployed) we are using from the following website https://urldefense.com/v3/__https://www.fdsn.org/networks/detail/7A_2008/*5Cn*22,*22metadata*22:*7B*7D,*22id*22:*229e42af2b*22*7D,*7B*22cell_type*22:*22code*22,*22source*22:*22stations_config__;JSUlJSUlJSUlJSUlJSUlJSUlJQ!!MbUpUFg_CiJxsA!bn3jhfl2ATXy0L7jCPnW3X8KHFwbEaCX-3k311Rlz-N22S0cF98qq2MTk3gr6of9pCQsgchvpcw1bMUms8Z5-Hvuos1p$  = dict(network='7A', #network name\n",
    "                       channel='EHZ', # we are only extracting vertical component data (this could take different forms, e.g. BHZ)\n",
    "                       starttime=UTC(2008, 1, 1), # collect data from this date to endtime\n",
    "                       endtime=UTC(2009, 1, 2),\n",
    "                       includerestricted=False,\n",
    "                       maxlatitude=3.5, # define search area for data\n",
    "                       minlatitude=1.5,\n",
    "                       minlongitude=97,\n",
    "                       maxlongitude=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DO NOT RUN THE CELL BELOW, UNLESS YOU REALLY WANT TO DOWNLOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the cell that will actually download the data. See SeisLib manual for all different options.\n",
    "downloader = ANDownloader(savedir='/Users/simone/iCloud/Documents/Teaching/2023_2024/Seismic_Tomography/Lab/download', \n",
    "                          inventory_name='7A.xml',\n",
    "                          provider='gfz',\n",
    "                          sampling_rate=1,\n",
    "                          prefilter=(0.005, 0.01, 0.5, 1),\n",
    "                          units='disp',\n",
    "                          attach_response=False,\n",
    "                          stations_config=stations_config,\n",
    "                          verbose=True)\n",
    "downloader.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now downloaded and stored the seismic records in the folder defined by savedir. We have our main ingredient to perform ambient noise tomography, the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Inter-Station Dispersion Curves\n",
    "\n",
    "At this stage, SeisLib is essentially ready to extract the dispersion curves. While it may appear that some steps are missing, SeisLib does everything in the background (e.g., computing the cross-correlations). More on the cells below, and obviously in the documentation of SeisLib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initiate the class AmbientNoiseVelocity by indicating the source folder containing the data and what component we are focusing on. You are most likely interested in the vertical component Z.\n",
    "src = 'download/data'\n",
    "an = AmbientNoiseVelocity(\n",
    "         src=src,\n",
    "         component='Z')\n",
    "print(an)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to prepare the data. The command below will extract information on each seismic receiver from the header of the sac files. These include (i) station coordinates and (ii) the time window spanned by the associated seismogram. The information is saved into two separate files, i.e., /path/to/an_velocity/Z/stations.pickle and /path/to/an_velocity/Z/timespans.pickle. These include (i) stations coordinates and (ii) the time window spanned by the associated seismograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "an.prepare_data()\n",
    "#an.plot_stations(resolution='10m') # If interested, this command will provide a rough plot of the stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dipersion analysis involves picking of the phase velocities around a reference curve, which needs to be provided by the user. \"rayleigh_asia.npy\" is a quite detailed curved already present in the main folder. If one needs to create their own reference curve, that can be easily done by building a two-dimensional numpy array containing frequency in the first column and velocity in the second (see commented example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_curve = np.load('rayleigh_asia.npy')\n",
    "print (ref_curve)\n",
    "#ref_curve= np.array([[0.001, 3.5],\n",
    "#                [0.05, 3.0],\n",
    "#                 [0.10, 2.5],\n",
    "#                 [0.15, 2.0],\n",
    "#                 [0.2, 2.0],\n",
    "#                 [0.5, 2.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic extraction of the dispersion curves for all available pairs of receivers.\n",
    "In class we have seen a relatively longer process and a number of recommendation, if you recall, that one should follow for extracting phase velocities once ambient noise data is acquired. Fortunately, the class extract_dispcurves does all that for us. I strongly suggest that you read the manual to find out more about this class, as there are a number of ways through which you can control the output and the processing. \n",
    "\n",
    "The results are saved to $self.savedir/dispcurves in .npy format, and consist of ndarrays of shape (n, 2), where the 1st column is frequency and the 2nd phase velocity (in m/s).\n",
    "\n",
    "The routine iterates over all the available combinations of station pairs and, for each one, (i) computes the cross spectrum (in the frequency domain) by ensamble averaging the cross correlations calculated over relatively small (and possibly overlapping, see overlap) time windows (see window_length), (ii) filters the cross-spectrum using a “velocity” filter, and (iii) extracts a smooth dispersion curve by comparison of the zero-crossings of the cross-spectrum with those of the Bessel function associated with the station pair in question.\n",
    "\n",
    "The below will calculate the dispersion curves for all combinations of station pairs for which the inter-station distance is < 1000 km and at least 30 days of simultaneous recordings are available. Cross-correlations will be computed in the frequency range 0.01-0.5 Hz on 50%-overlapping time windows. The results (ndarrays of shape (m, 2), where the 1st column is frequency and the 2nd is phase velocity) will be saved to /path/to/an_velocity/Z/dispcurves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an.extract_dispcurves(refcurve=ref_curve, \n",
    "                      freqmin=0.01, \n",
    "                      freqmax=0.5, \n",
    "                      cmin=1.5,\n",
    "                      cmax=4.0, \n",
    "                      distmax=1000, \n",
    "                      window_length=3600, \n",
    "                      overlap=0.5, \n",
    "                      min_no_days=30,\n",
    "                      save_xcorr=True, # If set to true, cross-correlations will be saved in a folder\n",
    "                      plotting=True) # If set to true, plots of cross-corr and dispersion curves will be shown progressively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting of the cross-correlations in the frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember we are working with the cross-spectrum here, essentially the Fourier transform of the cross-correlation of two signals.\n",
    "xcorr = np.load('download/an_velocity/Z/xcorr/7A.LT01..EHZ__7A.LT06..EHZ.npy')\n",
    "\n",
    "#Plot the real and ima\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(xcorr[:,0], xcorr[:,1].real, 'k', lw=1.5, label='Real')\n",
    "plt.plot(xcorr[:,0], xcorr[:,1].imag, 'gray', lw=1.5, label='Imag')\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.legend(loc='upper right', framealpha=0.9, handlelength=1)\n",
    "plt.title('Cross Spectrum')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tomographic inversion\n",
    "\n",
    "Once the extraction of the inter-station phase velocities is completed, it's extremely easy to prepare the inputs for the period-dependent tomographic inversions. This involves creating a number of input files for each period we want to perform tomography. The command below will create three files for period 4, 8 and 12, and save the input files in the savedir folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = 'download/an_velocity/tomo'\n",
    "periods = [4, 8, 12]\n",
    "an.prepare_input_tomography(savedir=savedir,\n",
    "                            period=periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, SeisLib discretizes the Earth’s surface by means of equal-area grids. These prevent from artificially increasing the resolution of the resulting tomographic maps at latitudes different than zero (the effect is more prominent nearby the poles), and should therefore be preferred to Cartesian grids when investigating relatively large areas. SeisLib also allows for adaptive parameterizations, with finer resolution in the areas characterized by relatively high density of measurements. If we consider a given block intersected by more than a certain number of inter-station great-circle paths, the finer resolution is achieved by splitting it in four sub-blocks, at the midpoint along both latitude an longitude. The operation can be performed an arbitrary number of times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will calculate a phase-velocity map at a given period (8 seconds in our case), based on inter-station measurements of surface-wave velocity. In practice, our data consist of a ndarray of shape (n, 5), where n is the number of inter-station measurements of phase velocity (extracted, for example, via seislib.an.an_velocity.AmbientNoiseVelocity), and the five columns consist of lat1 (°), lon1 (°), lat2 (°), lon2 (°), and velocity (m/s), respectively. (-180<=lon<180, -90<=lat<90). This matrix has been saved to /path/to/data.txt\n",
    "\n",
    "We will discretize the study area using an equal-area parameterization, characterized by blocks of 0.5˚ times 0.5˚. We will then iteratively refine the parameterization up to a maximum number of 2 times, to reach a maximum resolution of 0.125° in the areas of the map characterized by a relatively large number of measurements. (This refinement can be carried out an arbitrary number of times.)\n",
    "\n",
    "First, we need to initialize the SeismicTomography instance and load our data into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from seislib.tomography import SeismicTomography\n",
    "tomo = SeismicTomography(cell_size=0.25, regular_grid=False, verbose=True)\n",
    "tomo.add_data(src='download/an_velocity/tomo/input_8.00s.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can restrict the boundaries of the (global) equal-area parameterization to the minimum and maximum latitude and longitude spanned by our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tomo.grid.set_boundaries(latmin=tomo.latmin_data,\n",
    "                             latmax=tomo.latmax_data,\n",
    "                             lonmin=tomo.lonmin_data,\n",
    "                             lonmax=tomo.lonmax_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done so, everything is ready to calculate the coefficients of the A matrix (i.e., of the data kernel), and to refine the parameterization up to two times in the areas characterized by a relatively high density of measurements. We will define such regions (i.e., model parameters) as those where there are at least 40 inter-station great-circle paths intersecting them. In doing so, we will remove the grid cells of 0.5° that are not intersected by at least one great-circle path (see the argument keep_empty_cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tomo.compile_coefficients(keep_empty_cells=True)\n",
    "tomo.refine_parameterization(hitcounts=40, # to refine the grid, can be repeted several times\n",
    "                              keep_empty_cells=True)    \n",
    "tomo.refine_parameterization(hitcounts=40, \n",
    "                              keep_empty_cells=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the velocity map, we now need to carry out the inversion. We will apply a roughness-damping regularization, using a roughness coefficient equal to 3e-3 (to select a proper roughness damping, check lcurve()). We then plot the retrieved velocity.\n",
    "Note that the solve method returns slowness, hence we took the inverse of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the StationXML file containing station information\n",
    "inventory = read_inventory(\"download/7A.xml\")\n",
    "\n",
    "# Extract station latitudes and longitudes for plotting\n",
    "lats = [station.latitude for station in inventory[0].stations]\n",
    "lons = [station.longitude for station in inventory[0].stations]\n",
    "\n",
    "# Your existing code for tomography plotting\n",
    "c = 1 / tomo.solve(rdamp=3e-3) # Inverse of slowness to get velocities. Damping equal to 3e-3 is used. \n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Mercator())\n",
    "ax.coastlines(resolution='10m', color='k', lw=1, zorder=100)\n",
    "img = tomo.colormesh(mesh=tomo.grid.mesh, #Plotting the tomographic model\n",
    "                     c=c,\n",
    "                     ax=ax,\n",
    "                     cmap='RdBu',\n",
    "                     shading='flat',\n",
    "                     edgecolors='face')\n",
    "map_boundaries = (tomo.grid.lonmin, tomo.grid.lonmax,\n",
    "                 tomo.grid.latmin, tomo.grid.latmax)\n",
    "ax.set_extent(map_boundaries, ccrs.PlateCarree())\n",
    "cb = fig.colorbar(img, ax=ax, orientation='horizontal', pad=0.05)\n",
    "cb.set_label(label='Phase velocity (m/s)', labelpad=10, fontsize=22)\n",
    "\n",
    "# Adding labels without visible gridlines\n",
    "gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, linewidth=0)\n",
    "gl.xlabels_top = False  # Turn off labels on top\n",
    "gl.ylabels_right = False  # Turn off labels on right\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "# Plotting the seismic stations\n",
    "ax.scatter(lons, lats, marker='v', color='r', transform=ccrs.PlateCarree(), zorder=5, label='Stations')\n",
    "ax.legend(loc='upper right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with what you see in the following publication:\n",
    "https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2010GL044211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to show the rayhit (i.e., colored cells based on number of ray crossing)\n",
    "\n",
    "raypaths = tomo.raypaths_per_pixel()\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Mercator())\n",
    "ax.coastlines(resolution='10m', color='k', lw=1, zorder=100)\n",
    "img = tomo.colormesh(mesh=tomo.grid.mesh, \n",
    "                    c=raypaths, \n",
    "                    ax=ax, \n",
    "                    cmap='cividis', \n",
    "                    shading='flat', \n",
    "                    edgecolors='face')\n",
    "map_boundaries = (tomo.grid.lonmin, tomo.grid.lonmax, \n",
    "                tomo.grid.latmin, tomo.grid.latmax)\n",
    "ax.set_extent(map_boundaries, ccrs.PlateCarree())  \n",
    "cb = make_colorbar(ax, img, orientation='horizontal')\n",
    "cb.set_label(label='Raycounts', labelpad=10, fontsize=22)\n",
    "\n",
    "# Plotting the seismic stations\n",
    "ax.scatter(lons, lats, marker='v', color='r', transform=ccrs.PlateCarree(), zorder=5, label='Stations')\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DONE AND PRETTY MUCH WORKING, SEE IF YOU WANT TO ADD SYNTETHIC TEST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
